{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation of Growth Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acknowledgement**: This notebook has been written by **[Mahdi E Kahou](https://sites.google.com/site/mahdiebrahimikahou/about-me)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sSvhLeMr1bb"
   },
   "source": [
    "Consider the canonical growth problem:\n",
    "\n",
    "$\\begin{align}\n",
    "\\quad & \\max_{\\{c_t\\}_{t=0}^\\infty } \\sum \\beta^t u(c_t)\\\\\n",
    "\\quad & \\text{s.t.}\\quad  k_{t+1} = f(k_t) + (1-\\delta) k_t -c_t,\\\\\n",
    "\\quad & k_{t+1} \\geq 0,\\\\\n",
    "\\quad & k_0 \\quad \\text{is given}.\n",
    "\\end{align}$\n",
    "\n",
    "The Euler equation can be written as:\n",
    "\n",
    "$\\begin{align}\n",
    "\\quad & u'(c_t) = \\beta u'(c_{t+1})\\big[f'(k_{t+1})+(1-\\delta)\\big].\n",
    "\\end{align}$\n",
    "\n",
    "To pin down the solution transversality condition is required:\n",
    "\n",
    "$\\begin{align}\n",
    "\\quad & \\lim_{T\\rightarrow \\infty} u'(c_T)k_{T+1} = 0.\n",
    "\\end{align}$\n",
    "\n",
    "The solution of this problem can be written as a **root** of the **functional operator**.\n",
    "\n",
    "$\\begin{align}\n",
    "\\quad & \\beta u'\\big(c(t+1)\\big)\\bigg[f'\\big(k(t+1)\\big)+(1-\\delta)\\bigg] - u'\\big(c(t)\\big) = 0, \\\\\n",
    "\\quad & f\\big(k(t)\\big) + (1-\\delta) k(t) -c(t) - k(t+1)  = 0,\\\\\n",
    "\\quad & k(0)-k_0 = 0.\n",
    "\\end{align}$\n",
    "\n",
    "This example assumes that\n",
    " 1. $u(c) = \\frac{c^{1-\\sigma}}{1-\\sigma}$, and $f(k) = k^\\alpha$,\n",
    "\n",
    " 2.  $\\sigma = 1$, $\\beta = 0.9$, $\\alpha = \\frac{1}{3}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages\n",
    "\n",
    "Installation instructions for the [d2l package](https://www.d2l.ai/chapter_installation/index.html) and the [PyTorch package](https://pytorch.org/multipy/main/setup.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOwcRaTB1XaI"
   },
   "source": [
    "```python\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torchsummary\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTZX-_dJAbQl"
   },
   "source": [
    "Define plotting setups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGSwyspHgq1m"
   },
   "source": [
    "```python\n",
    "\n",
    "fontsize= 14\n",
    "ticksize = 14\n",
    "figsize = (12, 4.5)\n",
    "params = {'font.family':'serif',\n",
    "    \"figure.figsize\":figsize,\n",
    "    'figure.dpi': 80,\n",
    "    'figure.edgecolor': 'k',\n",
    "    'font.size': fontsize,\n",
    "    'axes.labelsize': fontsize,\n",
    "    'axes.titlesize': fontsize,\n",
    "    'xtick.labelsize': ticksize,\n",
    "    'ytick.labelsize': ticksize\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5Hj6u3Yg-Vk"
   },
   "source": [
    "Setting up the model's parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sr61pGbUg0F3"
   },
   "source": [
    "```python\n",
    "\n",
    "class Params(d2l.HyperParameters):\n",
    "    def __init__(self,\n",
    "                 alpha = 1.0/3.0,\n",
    "                 beta = 0.9,\n",
    "                 delta = 0.1,\n",
    "                 k_0 = 1.0,\n",
    "                ):\n",
    "        self.save_hyperparameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXQRWgay3dZ1"
   },
   "source": [
    "Define some useful functions:\n",
    "\n",
    "$f(k)$: Production function\n",
    "\n",
    "$f'(k)$: derivative of the production function\n",
    "\n",
    "$SS$: Steady states of the capital and consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7wLd10NkbTq"
   },
   "source": [
    "```python\n",
    "\n",
    "def f(k):\n",
    "    alpha = Params().alpha\n",
    "    return k**alpha\n",
    "\n",
    "def f_prime(k):\n",
    "    alpha = Params().alpha\n",
    "    return  alpha*(k**(alpha -1))\n",
    "\n",
    "def u_prime(c):\n",
    "    out = c.pow(-1)\n",
    "    return out\n",
    "\n",
    "class SS: #steady state\n",
    "    def __init__(self):\n",
    "        self.delta = Params().delta\n",
    "        self.beta = Params().beta\n",
    "        self.alpha = Params().alpha\n",
    "        base = ((1.0/self.beta)-1.0+self.delta)/self.alpha\n",
    "        exponent = 1.0/(self.alpha-1)\n",
    "        self.k_ss = base**exponent\n",
    "        self.c_ss = f(self.k_ss)-self.delta*self.k_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYAZeyHP4sHQ"
   },
   "source": [
    "### Preparing grid and data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft0GO0FEhJ5F"
   },
   "source": [
    "```python\n",
    "\n",
    "class Grid_data(d2l.HyperParameters):\n",
    "    def __init__(self,\n",
    "                 max_T = 32,\n",
    "                 batch_size = 8):\n",
    "        self.save_hyperparameters()\n",
    "        self.time_range = torch.arange(0.0, self.max_T , 1.0)\n",
    "        self.grid = self.time_range.unsqueeze(dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "class Data_label(Dataset):\n",
    "\n",
    "    def __init__(self,data):\n",
    "        self.time = data\n",
    "        self.n_samples = self.time.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "            return self.time[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsNuZCIQi91g"
   },
   "source": [
    "```python\n",
    "\n",
    "train_data = Grid_data().grid\n",
    "train_labeled = Data_label(train_data)\n",
    "train = DataLoader(dataset = train_labeled, batch_size = 8 , shuffle = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzFqPQ7om54A"
   },
   "source": [
    "### Defining structure of neural network\n",
    "\n",
    "Here the the approximation function (deep neural net) is $\\hat{q}=[\\hat{c},\\hat{k}] : \\mathbb{R} â†’ \\mathbb{R}^2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i1FttSJm5Fm"
   },
   "source": [
    "```python\n",
    "\n",
    "class NN(nn.Module, d2l.HyperParameters):\n",
    "    def __init__(self,\n",
    "                 dim_hidden = 128,\n",
    "                layers = 4,\n",
    "                hidden_bias = True):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        module = []\n",
    "        module.append(nn.Linear(1,self.dim_hidden, bias = self.hidden_bias))\n",
    "        module.append(nn.Tanh())\n",
    "\n",
    "        for i in range(self.layers-1):\n",
    "            module.append(nn.Linear(self.dim_hidden,self.dim_hidden, bias = self.hidden_bias))\n",
    "            module.append(nn.Tanh())\n",
    "\n",
    "        module.append(nn.Linear(self.dim_hidden,2))\n",
    "        module.append(nn.Softplus(beta = 1.0)) #The softplus layer ensures c>0,k>0\n",
    "\n",
    "        self.q = nn.Sequential(*module)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.q(x) # first element is consumption, the second element is capital\n",
    "        return  out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# Alternative Neural Network with ReLU activation functions\n",
    "\"\"\" class NN(nn.Module, d2l.HyperParameters):\n",
    "    def __init__(self,\n",
    "                 dim_hidden = 128,\n",
    "                layers = 4,\n",
    "                hidden_bias = True):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        module = []\n",
    "        module.append(nn.Linear(1,self.dim_hidden, bias = self.hidden_bias))\n",
    "        module.append(nn.ReLU())\n",
    "\n",
    "        for i in range(self.layers-1):\n",
    "            module.append(nn.Linear(self.dim_hidden,self.dim_hidden, bias = self.hidden_bias))\n",
    "            module.append(nn.ReLU())\n",
    "\n",
    "        module.append(nn.Linear(self.dim_hidden,2))\n",
    "        module.append(nn.Softplus(beta = 1.0)) #The softplus layer ensures c>0,k>0\n",
    "\n",
    "        self.q = nn.Sequential(*module)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.q(x) # first element is consumption, the second element is capital\n",
    "        return  out \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYhM3lBjnK4g"
   },
   "source": [
    "### Optimization of neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbPjjGe6nckC"
   },
   "source": [
    "Auxiliary function that extracts the learning rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p64tYIjouF3Y"
   },
   "source": [
    "```python\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "class Data_label(Dataset):\n",
    "\n",
    "    def __init__(self,data):\n",
    "        self.time = data\n",
    "        self.n_samples = self.time.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "            return self.time[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBEghCPun6DC"
   },
   "source": [
    "Initializing the neural net and defining the optimizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGDMXNCWn4eH"
   },
   "source": [
    "```python\n",
    "\n",
    "q_hat= NN()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(q_hat.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "print(q_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Untitled](_images/Network1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# Torchsummary provides a more readable summary of the neural network\n",
    "torchsummary.summary(q_hat, input_size=(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Untitled](_images/Network2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization of the network's weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA3rkyqSpFxa"
   },
   "source": [
    "```python\n",
    "\n",
    "delta = Params().delta\n",
    "beta = Params().beta\n",
    "k_0 = Params().k_0\n",
    "\n",
    "num_epochs = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEXzo6b5oUtw",
    "outputId": "9357cc89-44e6-4661-867a-4e9e0f748a03"
   },
   "source": [
    "```python\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, time in enumerate(train):\n",
    "        time_zero = torch.zeros([1,1])\n",
    "        time_next = time+1\n",
    "        c_t = q_hat(time)[:,[0]]\n",
    "        k_t = q_hat(time)[:,[1]]\n",
    "        c_tp1 = q_hat(time_next)[:,[0]]\n",
    "        k_tp1 = q_hat(time_next)[:,[1]]\n",
    "        k_t0 = q_hat(time_zero)[0,1]\n",
    "\n",
    "        res_1 = c_t-f(k_t)-(1-delta)*k_t + k_tp1 #Budget constraint\n",
    "        res_2 = (u_prime(c_t)/u_prime(c_tp1)) - beta*(f_prime(k_tp1)+1-delta) #Euler\n",
    "        res_3 = k_t0-k_0 #Initial Condition\n",
    "\n",
    "        loss_1 = res_1.pow(2).mean()\n",
    "        loss_2 = res_2.pow(2).mean()\n",
    "        loss_3 = res_3.pow(2).mean()\n",
    "        loss = 0.1*loss_1+0.8*loss_2+0.1*loss_3\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch == 0:\n",
    "         print('epoch' , ',' , 'loss' , ',', 'loss_bc' , ',' , 'loss_euler' , ',' , 'loss_initial' ,\n",
    "               ',', 'lr_rate')\n",
    "    if epoch % 100 == 0:\n",
    "          print(epoch,',',\"{:.2e}\".format(loss.detach().numpy()),',',\n",
    "                \"{:.2e}\".format(loss_1.detach().numpy()) , ',' , \"{:.2e}\".format(loss_2.detach().numpy())\n",
    "               , ',' , \"{:.2e}\".format(loss_3.detach().numpy()), ',', \"{:.2e}\".format(get_lr(optimizer)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_-xIWOtposn"
   },
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNucEUzNpCOY"
   },
   "source": [
    "```python\n",
    "\n",
    "time_test = Grid_data().grid\n",
    "c_hat_path = q_hat(time_test)[:,[0]].detach()\n",
    "k_hat_path = q_hat(time_test)[:,[1]].detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "fqLuZaubptde",
    "outputId": "7b2bb1a4-f444-435e-b641-c46b1c101fb8"
   },
   "source": [
    "```python\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.plot(time_test,k_hat_path, color='k',  label = r\"Approximate capital path\")\n",
    "plt.axhline(y=SS().k_ss, linestyle='--',color='k', label=\"k Steady State\")\n",
    "plt.ylabel(r\"k(t)\")\n",
    "plt.xlabel(r\"Time(t)\")\n",
    "plt.ylim([Params().k_0-0.1,SS().k_ss+0.1 ])\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(time_test,c_hat_path,label= r\"Approximate consumption path\")\n",
    "plt.axhline(y=SS().c_ss, linestyle='--',label=\"c Steady State\")\n",
    "plt.xlabel(r\"Time(t)\")\n",
    "plt.ylim([c_hat_path[0]-0.1,SS().k_ss+0.1 ])\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Untitled](_images/Fit_DL.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}